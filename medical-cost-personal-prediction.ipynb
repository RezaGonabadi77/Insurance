{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-17T15:23:34.430541Z","iopub.execute_input":"2023-04-17T15:23:34.431451Z","iopub.status.idle":"2023-04-17T15:23:34.450110Z","shell.execute_reply.started":"2023-04-17T15:23:34.431412Z","shell.execute_reply":"2023-04-17T15:23:34.448880Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/insurance/insurance.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Import Libraries and packages\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.metrics import mean_squared_error","metadata":{"execution":{"iopub.status.busy":"2023-04-17T15:23:34.455925Z","iopub.execute_input":"2023-04-17T15:23:34.456750Z","iopub.status.idle":"2023-04-17T15:23:36.579039Z","shell.execute_reply.started":"2023-04-17T15:23:34.456713Z","shell.execute_reply":"2023-04-17T15:23:36.577514Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Load data","metadata":{}},{"cell_type":"code","source":"# Load the time series data into a pandas dataframe\nData = pd.read_csv(r'/kaggle/input/insurance/insurance.csv')\ndata = pd.DataFrame(Data)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T15:23:36.581070Z","iopub.execute_input":"2023-04-17T15:23:36.581444Z","iopub.status.idle":"2023-04-17T15:23:36.606693Z","shell.execute_reply.started":"2023-04-17T15:23:36.581410Z","shell.execute_reply":"2023-04-17T15:23:36.605093Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2023-04-17T15:23:36.610887Z","iopub.execute_input":"2023-04-17T15:23:36.611437Z","iopub.status.idle":"2023-04-17T15:23:36.653424Z","shell.execute_reply.started":"2023-04-17T15:23:36.611381Z","shell.execute_reply":"2023-04-17T15:23:36.651820Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"      age     sex     bmi  children smoker     region      charges\n0      19  female  27.900         0    yes  southwest  16884.92400\n1      18    male  33.770         1     no  southeast   1725.55230\n2      28    male  33.000         3     no  southeast   4449.46200\n3      33    male  22.705         0     no  northwest  21984.47061\n4      32    male  28.880         0     no  northwest   3866.85520\n...   ...     ...     ...       ...    ...        ...          ...\n1333   50    male  30.970         3     no  northwest  10600.54830\n1334   18  female  31.920         0     no  northeast   2205.98080\n1335   18  female  36.850         0     no  southeast   1629.83350\n1336   21  female  25.800         0     no  southwest   2007.94500\n1337   61  female  29.070         0    yes  northwest  29141.36030\n\n[1338 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>bmi</th>\n      <th>children</th>\n      <th>smoker</th>\n      <th>region</th>\n      <th>charges</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>19</td>\n      <td>female</td>\n      <td>27.900</td>\n      <td>0</td>\n      <td>yes</td>\n      <td>southwest</td>\n      <td>16884.92400</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>18</td>\n      <td>male</td>\n      <td>33.770</td>\n      <td>1</td>\n      <td>no</td>\n      <td>southeast</td>\n      <td>1725.55230</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>28</td>\n      <td>male</td>\n      <td>33.000</td>\n      <td>3</td>\n      <td>no</td>\n      <td>southeast</td>\n      <td>4449.46200</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>33</td>\n      <td>male</td>\n      <td>22.705</td>\n      <td>0</td>\n      <td>no</td>\n      <td>northwest</td>\n      <td>21984.47061</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>32</td>\n      <td>male</td>\n      <td>28.880</td>\n      <td>0</td>\n      <td>no</td>\n      <td>northwest</td>\n      <td>3866.85520</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1333</th>\n      <td>50</td>\n      <td>male</td>\n      <td>30.970</td>\n      <td>3</td>\n      <td>no</td>\n      <td>northwest</td>\n      <td>10600.54830</td>\n    </tr>\n    <tr>\n      <th>1334</th>\n      <td>18</td>\n      <td>female</td>\n      <td>31.920</td>\n      <td>0</td>\n      <td>no</td>\n      <td>northeast</td>\n      <td>2205.98080</td>\n    </tr>\n    <tr>\n      <th>1335</th>\n      <td>18</td>\n      <td>female</td>\n      <td>36.850</td>\n      <td>0</td>\n      <td>no</td>\n      <td>southeast</td>\n      <td>1629.83350</td>\n    </tr>\n    <tr>\n      <th>1336</th>\n      <td>21</td>\n      <td>female</td>\n      <td>25.800</td>\n      <td>0</td>\n      <td>no</td>\n      <td>southwest</td>\n      <td>2007.94500</td>\n    </tr>\n    <tr>\n      <th>1337</th>\n      <td>61</td>\n      <td>female</td>\n      <td>29.070</td>\n      <td>0</td>\n      <td>yes</td>\n      <td>northwest</td>\n      <td>29141.36030</td>\n    </tr>\n  </tbody>\n</table>\n<p>1338 rows Ã— 7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Convert categorical features to numerical features","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n\n# select only categorical columns\ncat_cols = data.select_dtypes(include=['object','category']).columns\n\n# apply label encoding to each column\nfor col in cat_cols:\n    le = LabelEncoder()\n    data[col] = le.fit_transform(data[col])\n\nprint(data)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T15:23:36.654916Z","iopub.execute_input":"2023-04-17T15:23:36.655266Z","iopub.status.idle":"2023-04-17T15:23:36.682430Z","shell.execute_reply.started":"2023-04-17T15:23:36.655233Z","shell.execute_reply":"2023-04-17T15:23:36.681303Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"      age  sex     bmi  children  smoker  region      charges\n0      19    0  27.900         0       1       3  16884.92400\n1      18    1  33.770         1       0       2   1725.55230\n2      28    1  33.000         3       0       2   4449.46200\n3      33    1  22.705         0       0       1  21984.47061\n4      32    1  28.880         0       0       1   3866.85520\n...   ...  ...     ...       ...     ...     ...          ...\n1333   50    1  30.970         3       0       1  10600.54830\n1334   18    0  31.920         0       0       0   2205.98080\n1335   18    0  36.850         0       0       2   1629.83350\n1336   21    0  25.800         0       0       3   2007.94500\n1337   61    0  29.070         0       1       1  29141.36030\n\n[1338 rows x 7 columns]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Seperate Classes and Features from each other","metadata":{}},{"cell_type":"code","source":"X = data.drop('charges', axis=1)\ny = data['charges']","metadata":{"execution":{"iopub.status.busy":"2023-04-17T15:23:36.683836Z","iopub.execute_input":"2023-04-17T15:23:36.684214Z","iopub.status.idle":"2023-04-17T15:23:36.691624Z","shell.execute_reply.started":"2023-04-17T15:23:36.684170Z","shell.execute_reply":"2023-04-17T15:23:36.690538Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# create a LinearRegression model and fit it to the training data\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# make predictions on the test data\ny_pred = model.predict(X_test)\n\n# calculate the mean squared error of the predictions\nmse = mean_squared_error(y_test, y_pred)\nprint(\"Mean squared error: \", mse)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T15:23:36.693185Z","iopub.execute_input":"2023-04-17T15:23:36.693907Z","iopub.status.idle":"2023-04-17T15:23:36.723449Z","shell.execute_reply.started":"2023-04-17T15:23:36.693860Z","shell.execute_reply":"2023-04-17T15:23:36.722356Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Mean squared error:  33635210.431178406\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"# normalize the features using StandardScaler\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\n\n# split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-17T15:23:36.725055Z","iopub.execute_input":"2023-04-17T15:23:36.725568Z","iopub.status.idle":"2023-04-17T15:23:36.737961Z","shell.execute_reply.started":"2023-04-17T15:23:36.725518Z","shell.execute_reply":"2023-04-17T15:23:36.736444Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Train the poly Regression","metadata":{}},{"cell_type":"code","source":"# create polynomial features\npoly = PolynomialFeatures(degree=2)\nX_train_poly = poly.fit_transform(X_train)\nX_test_poly = poly.fit_transform(X_test)\n\n# create a LinearRegression model and fit it to the training data\nmodel = LinearRegression()\nmodel.fit(X_train_poly, y_train)\n\n# calculate the p-values of the coefficients\nX_train_poly_with_constant = sm.add_constant(X_train_poly)\nmodel_with_constant = sm.OLS(y_train, X_train_poly_with_constant)\nresults = model_with_constant.fit()\nprint(results.summary())","metadata":{"execution":{"iopub.status.busy":"2023-04-17T15:23:55.728733Z","iopub.execute_input":"2023-04-17T15:23:55.729176Z","iopub.status.idle":"2023-04-17T15:23:55.796599Z","shell.execute_reply.started":"2023-04-17T15:23:55.729144Z","shell.execute_reply":"2023-04-17T15:23:55.794912Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                charges   R-squared:                       0.841\nModel:                            OLS   Adj. R-squared:                  0.837\nMethod:                 Least Squares   F-statistic:                     220.1\nDate:                Mon, 17 Apr 2023   Prob (F-statistic):               0.00\nTime:                        15:23:55   Log-Likelihood:                -10588.\nNo. Observations:                1070   AIC:                         2.123e+04\nDf Residuals:                    1044   BIC:                         2.136e+04\nDf Model:                          25                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst       2.051e+14   1.07e+16      0.019      0.985   -2.07e+16    2.11e+16\nx1          3601.9705    157.458     22.876      0.000    3293.000    3910.941\nx2         -4.872e+12   2.54e+14     -0.019      0.985   -5.02e+14    4.93e+14\nx3          1977.9299    159.459     12.404      0.000    1665.034    2290.826\nx4           892.5926    206.685      4.319      0.000     487.028    1298.157\nx5         -4.057e+13   2.11e+15     -0.019      0.985   -4.18e+15     4.1e+15\nx6          -459.8658    151.265     -3.040      0.002    -756.683    -163.049\nx7           780.5587    184.069      4.241      0.000     419.371    1141.747\nx8           123.9231    151.181      0.820      0.413    -172.730     420.576\nx9            74.4364    155.389      0.479      0.632    -230.474     379.347\nx10          -77.5652    161.407     -0.481      0.631    -394.284     239.154\nx11           19.7172    152.495      0.129      0.897    -279.514     318.948\nx12          312.7461    152.766      2.047      0.041      12.982     612.510\nx13        -2.328e+14   1.21e+16     -0.019      0.985    -2.4e+16    2.35e+16\nx14           84.7238    154.789      0.547      0.584    -219.009     388.457\nx15         -156.5859    149.600     -1.047      0.295    -450.137     136.965\nx16           84.0059    152.724      0.550      0.582    -215.676     383.687\nx17          125.0028    150.226      0.832      0.406    -169.776     419.782\nx18         -284.4095    118.809     -2.394      0.017    -517.542     -51.277\nx19           70.8973    159.086      0.446      0.656    -241.267     383.062\nx20         3549.7541    154.662     22.952      0.000    3246.270    3853.238\nx21         -250.7109    161.986     -1.548      0.122    -568.567      67.145\nx22         -134.0361    133.234     -1.006      0.315    -395.472     127.400\nx23         -203.4576    156.854     -1.297      0.195    -511.243     104.327\nx24         -289.9389    145.922     -1.987      0.047    -576.273      -3.604\nx25         2.773e+13   1.44e+15      0.019      0.985    -2.8e+15    2.86e+15\nx26          172.3907    154.766      1.114      0.266    -131.296     476.078\nx27          128.0511    184.097      0.696      0.487    -233.190     489.293\n==============================================================================\nOmnibus:                      569.089   Durbin-Watson:                   2.063\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             3343.773\nSkew:                           2.483   Prob(JB):                         0.00\nKurtosis:                      10.095   Cond. No.                     2.59e+15\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The smallest eigenvalue is 1.33e-27. This might indicate that there are\nstrong multicollinearity problems or that the design matrix is singular.\n","output_type":"stream"}]}]}